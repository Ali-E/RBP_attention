{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "architectural-sarah",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'python'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a63a32530544>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'python'"
     ]
    }
   ],
   "source": [
    "import python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "english-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "educated-journey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([916, 17737])\n",
      "916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "assert(torch.cuda.is_available())\n",
    "device = \"cuda\"\n",
    "# device = \"cpu\"\n",
    "\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import seaborn as sns\n",
    "sns.set() # nice default plot formatting\n",
    "\n",
    "path_to_assigment_dir = Path(\"/content/drive/My Drive/Courses/ML for genomics/HWs/\")\n",
    "path_to_assigment_dir = Path(\"\")\n",
    "\n",
    "express_all = pd.read_csv(path_to_assigment_dir / \"Cell_line_RMA_proc_basalExp.txt.zip\", sep = \"\\t\")\n",
    "express_all.iloc[:6,:8]\n",
    "\n",
    "\n",
    "ic50_all = pd.read_csv(path_to_assigment_dir / \"TableS4A_ic50.txt.gz\", sep = \"\\t\", index_col = 0)\n",
    "ic50_all.iloc[:6,:8]\n",
    "\n",
    "\n",
    "common_cell_lines = [\"DATA.%i\" % g for g in ic50_all.index]\n",
    "common_cell_lines = list(set(common_cell_lines).intersection( express_all.columns.tolist() ))\n",
    "common_cell_lines = sorted(common_cell_lines) # required for reproducibility, set order is undefined\n",
    "expression = express_all[common_cell_lines]\n",
    "expression.shape\n",
    "\n",
    "\n",
    "cosmic_ids = [int(g[5:]) for g in common_cell_lines]\n",
    "ic50 = ic50_all.loc[cosmic_ids,:]\n",
    "ic50.shape\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "np.isnan(ic50.iloc[:,1:]).mean().mean()\n",
    "\n",
    "\n",
    "y_all = ic50[\"PFI-1\"]\n",
    "is_missing = np.isnan(y_all) # nan values = missing\n",
    "y_unnorm = torch.tensor(y_all[~is_missing].to_numpy(), device = device, dtype = torch.float)\n",
    "y = (y_unnorm - y_unnorm.mean()) / y_unnorm.std() # normalize\n",
    "\n",
    "X_all = expression.to_numpy().transpose() # X should be [N x P]\n",
    "X_unnorm = torch.tensor(X_all[~is_missing,:], device = device, dtype = torch.float)\n",
    "X = (X_unnorm - X_unnorm.mean(0, keepdims=True)) / X_unnorm.std(0, keepdims=True)\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "N = len(y)\n",
    "print(N)\n",
    "np.random.seed(1234) # for reproducibility\n",
    "rand_perm = np.random.permutation(N)\n",
    "train_idx = rand_perm[:int(np.ceil(0.8 * N))]\n",
    "val_idx = rand_perm[int(np.ceil(0.8 * N)):int(np.ceil(0.9 * N))]\n",
    "test_idx = rand_perm[int(np.ceil(0.9 * N)):]\n",
    "\n",
    "X_train = X[train_idx,:]\n",
    "X_val = X[val_idx,:]\n",
    "X_test = X[test_idx,:]\n",
    "\n",
    "y_train = y[train_idx]\n",
    "y_val = y[val_idx]\n",
    "y_test = y[test_idx]\n",
    "\n",
    "# rand_perm[:10]\n",
    "\n",
    "\n",
    "def ridge_regression(X, y, lamb):\n",
    "    beta,_ = torch.solve(X.transpose(0,1)@y[:, None], \n",
    "        X.transpose(0,1) @ X + \n",
    "        X.shape[0]*lamb*torch.eye(X.shape[1], device=X.device))\n",
    "    return(beta[:,0]) # matrix -> vector\n",
    "\n",
    "beta = ridge_regression(X_train, y_train, lamb = 1.)\n",
    "assert( np.abs(beta.std().item() - 0.0018369749886915088 ) < 1e-6 )\n",
    "\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import seaborn as sns\n",
    "sns.set() # nice default plot formatting\n",
    "\n",
    "lambdas = 10 ** np.arange(-2, 5, step = 0.5)\n",
    "val_rmse = np.zeros_like(lambdas)\n",
    "\n",
    "for i,lamb in enumerate(lambdas): # try different settings of lambda\n",
    "    beta = ridge_regression( X_train, y_train, lamb )\n",
    "    pred_val = X_val @ beta # make predictions on the validation set\n",
    "    val_rmse[i] = np.sqrt(torch.mean((y_val - pred_val)**2).item()) # item() gets the scalar value\n",
    "\n",
    "plt.plot(np.log10(lambdas), val_rmse)\n",
    "plt.xlabel(\"log10(lambda)\")\n",
    "plt.ylabel(\"Validation RMSE\")\n",
    "plt.savefig(\"ridge_regression_rmse.png\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
