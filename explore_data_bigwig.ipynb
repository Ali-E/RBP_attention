{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exclusive-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyBigWig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "quiet-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "# native_exon_inclusion_file = \"Data/se_splice_data/HepG2_natively_included_cassette_exons\"\n",
    "# native_exon_exclusion_file = \"Data/se_splice_data/HepG2_natively_excluded_cassette_exons\"\n",
    "\n",
    "native_exon_inclusion_file = \"Data/se_splice_data/K562_natively_included_cassette_exons\"\n",
    "native_exon_exclusion_file = \"Data/se_splice_data/K562_natively_excluded_cassette_exons\"\n",
    "native_exon_all_file = \"Data/se_splice_data/K562_native_cassette_exons_all\"\n",
    "native_exon_constitutive_file = \"Data/se_splice_data/K562_constitutive_exons\"\n",
    "\n",
    "CONST = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "differential-scope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          annotation           low_exon  \\\n",
      "0  chr1|-|1653150-1654026|1654073-1654146|1653150...    1653034-1653150   \n",
      "1  chr1|-|1688047-1688217|1688321-1688619|1688047...    1687941-1688047   \n",
      "2  chr1|-|2121220-2124283|2124414-2125077|2121220...    2121151-2121220   \n",
      "3  chr1|+|10165802-10166254|10166641-10177516|101...  10165573-10165802   \n",
      "4  chr1|+|11805894-11806183|11806280-11807496|118...  11805859-11805894   \n",
      "\n",
      "        skipped_exon            hi_exon       incl         excl  \n",
      "0    1654026-1654073    1654146-1654270  2192,7868  17572,63166  \n",
      "1    1688217-1688321    1688619-1688707   693,4821   5748,33635  \n",
      "2    2124283-2124414    2125077-2125349   986,2600   8067,21547  \n",
      "3  10166254-10166641  10177516-10177658   388,2672   3166,18937  \n",
      "4  11806183-11806280  11807496-11807602  1152,3470   9400,25577  \n"
     ]
    }
   ],
   "source": [
    "df_ex_inc = pd.read_csv(native_exon_inclusion_file, sep='\\t')\n",
    "df_ex_exc = pd.read_csv(native_exon_exclusion_file, sep='\\t')\n",
    "df_ex_con = pd.read_csv(native_exon_constitutive_file, sep='\\t')\n",
    "df_ex_all = pd.read_csv(native_exon_all_file, sep='\\t')\n",
    "print(df_ex_exc.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-deviation",
   "metadata": {},
   "source": [
    "## Compute PSI values for exons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "round-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_psi(row, exp_num, read_length=100):\n",
    "    inc_exc_1 = row['incl'] # incl, excl labels seem to be inaccurate in the original files!\n",
    "    inc_exc_2 = row['excl']\n",
    "    inc_exc = [inc_exc_1, inc_exc_2]\n",
    "    \n",
    "    inc, exc = [int(num) for num in inc_exc[exp_num].split(',')]\n",
    "    \n",
    "    exon_start, exon_end = [int(num) for num in row['skipped_exon'].split('-')]\n",
    "    exon_length = exon_end-exon_start+1\n",
    "    \n",
    "    # IR_norm = inc/(exon_length + read_length - 1.)\n",
    "    IR_norm = inc/(read_length - 1.)\n",
    "    ER_norm = exc/(read_length - 1.)\n",
    "    \n",
    "    psi = IR_norm/(IR_norm+ER_norm)\n",
    "    return psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "facial-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_length(row):\n",
    "    exon_start, exon_end = [int(num) for num in row['skipped_exon'].split('-')]\n",
    "    exon_length = exon_end-exon_start+1\n",
    "    return exon_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pressed-serum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.769019537205901\n",
      "0.9769866729369965\n",
      "0.9284718275865678\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ex_inc['psi_1'] = df_ex_inc.apply(lambda row: compute_psi(row, 0), axis=1)\n",
    "df_ex_inc['psi_2'] = df_ex_inc.apply(lambda row: compute_psi(row, 1), axis=1)\n",
    "df_ex_inc['length'] = df_ex_inc.apply(lambda row: compute_length(row), axis=1)\n",
    "df_ex_inc['avg'] = (df_ex_inc['psi_1'] + df_ex_inc['psi_2'])/2.\n",
    "# print(df_ex_inc.head())\n",
    "\n",
    "plt.hist(df_ex_inc['avg'], bins=30)\n",
    "print(min(df_ex_inc['avg']))\n",
    "print(max(df_ex_inc['avg']))\n",
    "print(np.mean(df_ex_inc['psi_1']))\n",
    "plt.savefig('including_psi_hist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "graduate-southeast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [annotation, low_exon, skipped_exon, hi_exon, incl, excl, psi_1, psi_2, length, avg]\n",
      "Index: []\n",
      "too long 16\n",
      "too short: 7\n",
      "4\n",
      "5081\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ex_inc_weird = df_ex_inc[df_ex_inc['avg'] < 0.5]\n",
    "print(df_ex_inc_weird)\n",
    "\n",
    "print('too long', len(df_ex_inc[df_ex_inc['length'] > 1000]))\n",
    "print('too short:', len(df_ex_inc[df_ex_inc['length'] < 20]))\n",
    "plt.hist(df_ex_inc['length'], bins=30)\n",
    "print(min(df_ex_inc['length']))\n",
    "print(max(df_ex_inc['length']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "balanced-insured",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09187691787054503\n",
      "0.5114636096143341\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ex_exc['psi_1'] = df_ex_exc.apply(lambda row: compute_psi(row, 0), axis=1)\n",
    "df_ex_exc['psi_2'] = df_ex_exc.apply(lambda row: compute_psi(row, 1), axis=1)\n",
    "df_ex_exc['avg'] = (df_ex_exc['psi_1'] + df_ex_exc['psi_2'])/2.\n",
    "# print(df_ex_exc.head())\n",
    "\n",
    "plt.hist(df_ex_exc['avg'], bins=30)\n",
    "print(min(df_ex_exc['avg']))\n",
    "print(max(df_ex_exc['avg']))\n",
    "plt.savefig('excluding_psi_hist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "satellite-demonstration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09264094955489614\n",
      "0.9768912987348309\n",
      "0.7667172481628632\n",
      "284\n",
      "417\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ex_all['psi_1'] = df_ex_all.apply(lambda row: compute_psi(row, 0), axis=1)\n",
    "df_ex_all['psi_2'] = df_ex_all.apply(lambda row: compute_psi(row, 1), axis=1)\n",
    "df_ex_all['length'] = df_ex_all.apply(lambda row: compute_length(row), axis=1)\n",
    "df_ex_all['avg'] = (df_ex_all['psi_1'] + df_ex_all['psi_2'])/2.\n",
    "# print(df_ex_inc.head())\n",
    "\n",
    "plt.hist(df_ex_all['avg'], bins=30)\n",
    "print(min(df_ex_all['psi_1']))\n",
    "print(max(df_ex_all['psi_1']))\n",
    "print(np.mean(df_ex_all['psi_1']))\n",
    "# plt.savefig('all_psi_hist.png')\n",
    "\n",
    "df_ex_all_filtered = df_ex_all[df_ex_all['avg'] >= 0.5114637]\n",
    "df_ex_all_filtered = df_ex_all_filtered[df_ex_all_filtered['avg'] <= 0.7690195]\n",
    "print(len(df_ex_all_filtered))\n",
    "\n",
    "exc_inc_rbps_set = set(df_ex_exc['annotation']) | set(df_ex_inc['annotation'])\n",
    "df_ex_all_filtered = df_ex_all[~ df_ex_all['annotation'].isin(exc_inc_rbps_set)]\n",
    "print(len(df_ex_all_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "graduate-capture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          stub    accession target  rep_num cell_name assembly strand\n",
      "0  ENCFF411IAE  ENCFF411IAE    SSB        2      K562     hg19  minus\n",
      "1  ENCFF131CHH  ENCFF131CHH    SSB        2      K562     hg19   plus\n",
      "2  ENCFF805UMW  ENCFF805UMW    SSB        1      K562     hg19   plus\n",
      "3  ENCFF623ASO  ENCFF623ASO    SSB        2      K562   GRCh38  minus\n",
      "4  ENCFF732TUI  ENCFF732TUI    SSB        1      K562   GRCh38  minus\n",
      "total RBPs considered: 239\n"
     ]
    }
   ],
   "source": [
    "meta_data_file = \"Data/RBPs/bigwig_files_metadata_sample.csv\"\n",
    "meta_data = pd.read_csv(meta_data_file)\n",
    "print(meta_data.head())\n",
    "meta_hg19 = meta_data[(meta_data[\"assembly\"]=='hg19') & (meta_data[\"cell_name\"]=='K562') & (meta_data[\"rep_num\"]==1)].reset_index(drop=True)\n",
    "# print(meta_hg19.head())\n",
    "print('total RBPs considered:', len(meta_hg19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "smoking-federal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:  239\n",
      "after:  72\n"
     ]
    }
   ],
   "source": [
    "#get known splicing RBPs from Megan's list\n",
    "splicing_RBPs = pd.read_excel('Data/RBP_list_Gerstberger.xls', sheet_name='RBP table')\n",
    "mask = splicing_RBPs.apply(lambda row: row.astype(str).str.contains('splicing').any(), axis=1)\n",
    "\n",
    "splicing_RBPs = splicing_RBPs.loc[mask]\n",
    "splicing_RBPs = set(splicing_RBPs['gene name'])\n",
    "# print(splicing_RBPs)\n",
    "\n",
    "print('before: ', len(meta_hg19))\n",
    "meta_hg19 = meta_hg19[meta_hg19['target'].isin(splicing_RBPs)]\n",
    "print('after: ', len(meta_hg19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "hollywood-thanksgiving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            stub    accession  target  rep_num cell_name assembly strand  \\\n",
      "229  ENCFF522WHU  ENCFF522WHU   SF3B1        1      K562     hg19  minus   \n",
      "230  ENCFF430PGG  ENCFF430PGG   SF3B1        1      K562     hg19   plus   \n",
      "134  ENCFF733YZJ  ENCFF733YZJ   LARP7        1      K562     hg19   plus   \n",
      "133  ENCFF058MZF  ENCFF058MZF   LARP7        1      K562     hg19  minus   \n",
      "127  ENCFF722NAD  ENCFF722NAD  ZRANB2        1      K562     hg19  minus   \n",
      "\n",
      "     site_count  \n",
      "229      574560  \n",
      "230      583416  \n",
      "134      799392  \n",
      "133      852864  \n",
      "127      990384  \n"
     ]
    }
   ],
   "source": [
    "chr_list = [\"chr\" + str(i+1) for i in range(22)] + [\"chrX\", \"chrY\"]\n",
    "\n",
    "rbp_dict = {}\n",
    "len_list = []\n",
    "len_dict = {}\n",
    "avg_len_list = []\n",
    "for idx, row in meta_hg19.iterrows():\n",
    "    stub = row[\"stub\"]\n",
    "    target = row[\"target\"]\n",
    "    strand = row[\"strand\"]\n",
    "    bw_file = \"Data/RBPs/bigwig_files/\"+ stub +\".bigWig\"\n",
    "    \n",
    "    bw = pyBigWig.open(bw_file)\n",
    "    \n",
    "    # df_rbp = pd.read_csv(rbp_file, header=None, sep='\\t')\n",
    "    # df_rbp['len'] = df_rbp[2] - df_rbp[1] + 1\n",
    "    # avg_len = np.mean(df_rbp['len'])\n",
    "    # avg_len_list.append(avg_len)\n",
    "    \n",
    "    if target in rbp_dict:\n",
    "        rbp_dict[target][strand] = bw\n",
    "    else:\n",
    "        rbp_dict[target] = {}\n",
    "        rbp_dict[target][strand] = bw\n",
    "        \n",
    "    len_cur = 0\n",
    "    for chro in chr_list:\n",
    "        len_cur += len(bw.intervals(\"chr1\"))\n",
    "    len_dict[target] = len_cur\n",
    "    len_list.append(len_cur)\n",
    "    \n",
    "    \n",
    "meta_hg19['site_count'] = len_list\n",
    "# meta_hg19['avg_len'] = avg_len_list\n",
    "meta_hg19 = meta_hg19.sort_values(by='site_count', ascending=True)\n",
    "print(meta_hg19.head())\n",
    "# print('max_avg_len:', np.max(meta_hg19['avg_len']))\n",
    "# print('min_avg_len:', np.min(meta_hg19['avg_len']))\n",
    "# print('avg_len:', np.mean(meta_hg19['avg_len']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "virtual-seafood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6., 4., 4., 1., 7., 6., 2., 7., 5., 2., 2., 2., 0., 2., 0., 0., 1.,\n",
       "        0., 1., 1., 5., 2., 2., 0., 1., 1., 2., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 1., 0., 0., 1., 3.]),\n",
       " array([  574560. ,  1166492.4,  1758424.8,  2350357.2,  2942289.6,\n",
       "         3534222. ,  4126154.4,  4718086.8,  5310019.2,  5901951.6,\n",
       "         6493884. ,  7085816.4,  7677748.8,  8269681.2,  8861613.6,\n",
       "         9453546. , 10045478.4, 10637410.8, 11229343.2, 11821275.6,\n",
       "        12413208. , 13005140.4, 13597072.8, 14189005.2, 14780937.6,\n",
       "        15372870. , 15964802.4, 16556734.8, 17148667.2, 17740599.6,\n",
       "        18332532. , 18924464.4, 19516396.8, 20108329.2, 20700261.6,\n",
       "        21292194. , 21884126.4, 22476058.8, 23067991.2, 23659923.6,\n",
       "        24251856. ]),\n",
       " <BarContainer object of 40 artists>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(meta_hg19['site_count'], bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "quality-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ex_inc['chr'] = df_ex_inc['annotation'].apply(lambda x: str(x).split(\"|\")[0])\n",
    "df_ex_inc['strand'] = df_ex_inc['annotation'].apply(lambda x: str(x).split(\"|\")[1])\n",
    "df_ex_inc['start'] = df_ex_inc['skipped_exon'].apply(lambda x: int(str(x).split(\"-\")[0]))\n",
    "df_ex_inc['end'] = df_ex_inc['skipped_exon'].apply(lambda x: int(str(x).split(\"-\")[1]))\n",
    "# print(df_ex_inc.head())\n",
    "df_ex_inc_pos = df_ex_inc[df_ex_inc['strand'] == '+']\n",
    "df_ex_inc_neg = df_ex_inc[df_ex_inc['strand'] == '-']\n",
    "\n",
    "# inc_pos_tups = list(zip(df_ex_inc_pos['chr'], zip(df_ex_inc_pos['start'], df_ex_inc_pos['end'])))\n",
    "# pos_end_tups = list(zip(df_ex_inc_pos['chr'], df_ex_inc_pos['end']))\n",
    "\n",
    "# inc_neg_tups = list(zip(df_ex_inc_neg['chr'], zip(df_ex_inc_neg['start'], df_ex_inc_neg['end'])))\n",
    "# neg_end_tups = list(zip(df_ex_inc_pos['chr'], df_ex_inc_neg['end']))\n",
    "# print(inc_neg_tups[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "juvenile-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ex_exc['chr'] = df_ex_exc['annotation'].apply(lambda x: str(x).split(\"|\")[0])\n",
    "df_ex_exc['strand'] = df_ex_exc['annotation'].apply(lambda x: str(x).split(\"|\")[1])\n",
    "df_ex_exc['start'] = df_ex_exc['skipped_exon'].apply(lambda x: int(str(x).split(\"-\")[0]))\n",
    "df_ex_exc['end'] = df_ex_exc['skipped_exon'].apply(lambda x: int(str(x).split(\"-\")[1]))\n",
    "# print(df_ex_exc.head())\n",
    "df_ex_exc_pos = df_ex_exc[df_ex_exc['strand'] == '+']\n",
    "df_ex_exc_neg = df_ex_exc[df_ex_exc['strand'] == '-']\n",
    "\n",
    "# exc_pos_tups = list(zip(df_ex_exc_pos['chr'], zip(df_ex_exc_pos['start'], df_ex_exc_pos['end'])))\n",
    "# exc_neg_tups = list(zip(df_ex_exc_neg['chr'], zip(df_ex_exc_neg['start'], df_ex_exc_neg['end'])))\n",
    "# print(exc_neg_tups[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "compound-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ex_con['chr'] = df_ex_con['annotation'].apply(lambda x: str(x).split(\"|\")[0])\n",
    "df_ex_con['strand'] = df_ex_con['annotation'].apply(lambda x: str(x).split(\"|\")[1])\n",
    "df_ex_con['start'] = df_ex_con['skipped_exon'].apply(lambda x: int(str(x).split(\"-\")[0]))\n",
    "df_ex_con['end'] = df_ex_con['skipped_exon'].apply(lambda x: int(str(x).split(\"-\")[1]))\n",
    "# print(df_ex_exc.head())\n",
    "df_ex_con_pos = df_ex_con[df_ex_con['strand'] == '+']\n",
    "df_ex_con_neg = df_ex_con[df_ex_con['strand'] == '-']\n",
    "\n",
    "# con_pos_tups = list(zip(df_ex_con_pos['chr'], zip(df_ex_con_pos['start'], df_ex_con_pos['end'])))\n",
    "# con_neg_tups = list(zip(df_ex_con_neg['chr'], zip(df_ex_con_neg['start'], df_ex_con_neg['end'])))\n",
    "# print(exc_neg_tups[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "absent-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tup_to_dict(tup_list):\n",
    "    res_dict = {}\n",
    "    for tup in tup_list:\n",
    "        if tup[0] in res_dict:\n",
    "            res_dict[tup[0]].append(tup[1])\n",
    "        else:\n",
    "            res_dict[tup[0]] = []\n",
    "            res_dict[tup[0]].append(tup[1])\n",
    "    return res_dict\n",
    "\n",
    "# inc_pos_dict = tup_to_dict(inc_pos_tups)\n",
    "# inc_neg_dict = tup_to_dict(inc_neg_tups)\n",
    "# print(inc_neg_dict.keys())\n",
    "\n",
    "\n",
    "# exc_pos_dict = tup_to_dict(exc_pos_tups)\n",
    "# exc_neg_dict = tup_to_dict(exc_neg_tups)\n",
    "\n",
    "# con_pos_dict = tup_to_dict(con_pos_tups)\n",
    "# con_neg_dict = tup_to_dict(con_neg_tups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "answering-belief",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exc_pos_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-46681ec1554a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcount_overlapping_exons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mchrom\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexc_pos_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minc_pos_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchrom\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtup1_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtup1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtup1_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exc_pos_dict' is not defined"
     ]
    }
   ],
   "source": [
    "count_overlapping_exons = 0\n",
    "for chrom in exc_pos_dict:\n",
    "    tups = inc_pos_dict[chrom]\n",
    "    for tup1_idx in range(len(tups)-1):\n",
    "        tup1 = tups[tup1_idx]\n",
    "        for tup2_idx in range(tup1_idx+1, len(tups)):\n",
    "            tup2 = tups[tup2_idx]\n",
    "            if tup1[0] < tup2[0] and tup1[1] > tup2[0]:\n",
    "                print(tup1, tup2)\n",
    "                count_overlapping_exons += 1 \n",
    "            elif tup2[0] < tup1[0] and tup2[1] > tup1[0]:\n",
    "                print(tup1, tup2)\n",
    "                count_overlapping_exons += 1 \n",
    "print('number of overlapping exons: ', count_overlapping_exons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_buckets(bw_rbp, df_exon, const=500):\n",
    "    bucket_right = np.zeros(const, dtype=float)\n",
    "    bucket_left = np.zeros(const, dtype=float)\n",
    "    for idx, row in df_exon.iterrows():\n",
    "        chromosom = row['chr']\n",
    "        start = row['start']\n",
    "        end = row['end']\n",
    "        \n",
    "        chr_len = bw_rbp.chroms()[chromosom]\n",
    "        \n",
    "        start_pos = max(start-const, 0)\n",
    "        end_pos = min(end+const, chr_len-1)\n",
    "        \n",
    "        values_left = np.array(bw_rbp.stats(chromosom, start_pos, start, nBins=start-start_pos))\n",
    "        values_left[values_left == None] = 0.\n",
    "        values_left = values_left.astype(float, copy=False)\n",
    "        \n",
    "        values_right = np.array(bw_rbp.stats(chromosom, end, end_pos, nBins=end_pos-end))\n",
    "        values_right[values_right == None] = 0.\n",
    "        values_right = values_right.astype(float, copy=False)\n",
    "        \n",
    "        # print(values_left.dtype)\n",
    "        # print(bucket_left.dtype)\n",
    "        bucket_left += values_left\n",
    "        bucket_right += values_right\n",
    "\n",
    "    return bucket_right, bucket_left\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-shakespeare",
   "metadata": {},
   "source": [
    "# Processing an RBP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rbp = rbp_dict['AQR']\n",
    "# print(df_rbp.head())\n",
    "df_rbp_pos = rbp_dict['AQR']['plus']\n",
    "df_rbp_neg = rbp_dict['AQR']['minus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-proportion",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_pos_bucket_right, inc_pos_bucket_left = get_buckets(df_rbp_pos, df_ex_inc_pos)\n",
    "inc_neg_bucket_left, inc_neg_bucket_right = get_buckets(df_rbp_neg, df_ex_inc_neg)\n",
    "\n",
    "inc_bucket_right = inc_pos_bucket_right + inc_neg_bucket_right\n",
    "inc_bucket_left = inc_pos_bucket_left + inc_neg_bucket_left\n",
    "\n",
    "# inc_bucket_right = 100*inc_bucket_right/np.sum(inc_bucket_right)\n",
    "# inc_bucket_left = 100*inc_bucket_left/np.sum(inc_bucket_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_bucket_right = np.abs(inc_bucket_right)\n",
    "inc_bucket_left = np.abs(inc_bucket_left)\n",
    "\n",
    "\n",
    "y_limit = max(max(inc_bucket_left), max(inc_bucket_right)) + 10\n",
    "y_min = min(min(inc_bucket_left), min(inc_bucket_right)) - 5\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.figure(figsize=(15, 4))\n",
    "ax_1 = plt.subplot(1, 2, 1)\n",
    "print(len(inc_bucket_left))\n",
    "ax_1.scatter([i for i in range(-CONST,0,1)], np.flip(inc_bucket_left))\n",
    "ax_1.set_ylim([y_min, y_limit])\n",
    "\n",
    "ax_2 = plt.subplot(1, 2, 2)\n",
    "ax_2.scatter([i for i in range(1,CONST+1,1)], inc_bucket_right)\n",
    "ax_2.set_ylim([y_min, y_limit])\n",
    "plt.savefig('inc_buckets.jpg', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "exc_pos_bucket_right, exc_pos_bucket_left = get_buckets(df_rbp_pos, df_ex_exc_pos)\n",
    "exc_neg_bucket_left, exc_neg_bucket_right = get_buckets(df_rbp_neg, df_ex_exc_neg)\n",
    "\n",
    "exc_bucket_right = exc_pos_bucket_right + exc_neg_bucket_right\n",
    "exc_bucket_left = exc_pos_bucket_left + exc_neg_bucket_left\n",
    "\n",
    "# exc_bucket_right = 100*exc_bucket_right/np.sum(exc_bucket_right)\n",
    "# exc_bucket_left = 100*exc_bucket_left/np.sum(exc_bucket_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "exc_bucket_right = np.abs(exc_bucket_right)\n",
    "exc_bucket_left = np.abs(exc_bucket_left)\n",
    "\n",
    "y_limit = max(max(exc_bucket_left), max(exc_bucket_right)) + 2\n",
    "y_min = min(min(exc_bucket_left), min(exc_bucket_right)) - 5\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "ax_1 = plt.subplot(1, 2, 1)\n",
    "ax_1.scatter([i for i in range(-CONST,0,1)], np.flip(exc_bucket_left))\n",
    "ax_1.set_ylim([y_min, y_limit])\n",
    "\n",
    "ax_2 = plt.subplot(1, 2, 2)\n",
    "ax_2.scatter([i for i in range(1,CONST+1,1)], exc_bucket_right)\n",
    "ax_2.set_ylim([y_min, y_limit])\n",
    "\n",
    "plt.savefig('exc_buckets.jpg', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-trade",
   "metadata": {},
   "source": [
    "# Processing all the RBPs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "sufficient-absorption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total count: 72\n",
      "max:  24251856\n",
      "min:  574560\n",
      "mean:  7620689.666666667\n",
      "less than 10:  0\n",
      "greater than 250:  72\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_len_list = len_list\n",
    "# for rbp_name in len_dict:\n",
    "#     all_len_list += len_dict[rbp_name]\n",
    "plt.hist(all_len_list, bins=50)\n",
    "print('total count:', len(all_len_list))\n",
    "print('max: ', np.max(all_len_list))\n",
    "print('min: ', np.min(all_len_list))\n",
    "print('mean: ', np.mean(all_len_list))\n",
    "print('less than 10: ', np.sum(np.array(all_len_list) < 10))\n",
    "print('greater than 250: ', np.sum(np.array(all_len_list) > 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "excess-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(rbps, df_exon, const=5000, strand='plus'):\n",
    "    rows = []\n",
    "    for rbp in rbps:\n",
    "        bw_rbp_both = rbps[rbp]\n",
    "        if strand not in bw_rbp_both:\n",
    "            print(rbp, strand)\n",
    "            continue\n",
    "            \n",
    "        bw_rbp = bw_rbp_both[strand]\n",
    "        \n",
    "        for exon_idx, row in df_exon.iterrows():\n",
    "            chromosom = row['chr']\n",
    "            start = row['start']\n",
    "            end = row['end']\n",
    "            chr_len = bw_rbp.chroms()[chromosom]\n",
    "\n",
    "            start_pos = max(start-const, 0)\n",
    "            end_pos = min(end+const, chr_len-1)\n",
    "            \n",
    "            intervals = bw_rbp.intervals(chromosom, start_pos, end_pos)\n",
    "            if intervals is None:\n",
    "                continue\n",
    "        \n",
    "            new_row = (exon_idx, chromosom, start, end, rbp, strand)\n",
    "            rows.append(new_row)\n",
    "                \n",
    "    df = pd.DataFrame(rows, columns=['exon_idx', 'chr', 'exon_start', 'exon_end', 'rbp', 'strand'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-payroll",
   "metadata": {},
   "source": [
    "## Run this section only if you do not want to use precomputed tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "protected-potter",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluding_pos_df = generate_data(rbp_dict, df_ex_exc_pos, const=5000, strand='plus')\n",
    "excluding_neg_df = generate_data(rbp_dict, df_ex_exc_neg, const=5000, strand='minus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "continental-subscriber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   exon_idx   chr  exon_start  exon_end     rbp strand\n",
      "0         3  chr1    10166254  10166641  GTF2F1   plus\n",
      "1         4  chr1    11806183  11806280  GTF2F1   plus\n",
      "2         8  chr1    22400586  22400712  GTF2F1   plus\n",
      "3         9  chr1    26438950  26439141  GTF2F1   plus\n",
      "4        11  chr1    28857034  28857085  GTF2F1   plus\n",
      "   exon_idx   chr  exon_start  exon_end     rbp strand\n",
      "0         0  chr1     1654026   1654073  GTF2F1  minus\n",
      "1         1  chr1     1688217   1688321  GTF2F1  minus\n",
      "2         2  chr1     2124283   2124414  GTF2F1  minus\n",
      "3         5  chr1    19472516  19472600  GTF2F1  minus\n",
      "4         6  chr1    21219111  21219222  GTF2F1  minus\n",
      "   exon_idx   chr  exon_start  exon_end     rbp strand\n",
      "0         3  chr1    10166254  10166641  GTF2F1   plus\n",
      "1         4  chr1    11806183  11806280  GTF2F1   plus\n",
      "2         8  chr1    22400586  22400712  GTF2F1   plus\n",
      "3         9  chr1    26438950  26439141  GTF2F1   plus\n",
      "4        11  chr1    28857034  28857085  GTF2F1   plus\n"
     ]
    }
   ],
   "source": [
    "# excluding_pos_df['strand'] = ['+' for i in range(len(excluding_pos_df))]\n",
    "print(excluding_pos_df.head())\n",
    "# excluding_neg_df['strand'] = ['-' for i in range(len(excluding_neg_df))]\n",
    "print(excluding_neg_df.head())\n",
    "excluding_df = pd.concat([excluding_pos_df, excluding_neg_df]).reset_index(drop=True)\n",
    "print(excluding_df.head())\n",
    "excluding_df.to_csv('excluding_df_bw_K562_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "duplicate-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "including_pos_df = generate_data(rbp_dict, df_ex_inc_pos, const=5000, strand='plus')\n",
    "including_neg_df = generate_data(rbp_dict, df_ex_inc_neg, const=5000, strand='minus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "controversial-twenty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   exon_idx   chr  exon_start  exon_end     rbp strand\n",
      "0         6  chr1     6880240   6880310  GTF2F1   plus\n",
      "1         8  chr1     9630315   9630416  GTF2F1   plus\n",
      "2         9  chr1    12042026  12042171  GTF2F1   plus\n",
      "3        10  chr1    12081701  12081897  GTF2F1   plus\n",
      "4        11  chr1    15753645  15753780  GTF2F1   plus\n",
      "   exon_idx   chr  exon_start  exon_end     rbp strand\n",
      "0         0  chr1     1203241   1203372  GTF2F1  minus\n",
      "1         1  chr1     1643702   1643839  GTF2F1  minus\n",
      "2         2  chr1     1685489   1685647  GTF2F1  minus\n",
      "3         3  chr1     1770628   1770677  GTF2F1  minus\n",
      "4         4  chr1     3753058   3753256  GTF2F1  minus\n",
      "   exon_idx   chr  exon_start  exon_end     rbp strand\n",
      "0         6  chr1     6880240   6880310  GTF2F1   plus\n",
      "1         8  chr1     9630315   9630416  GTF2F1   plus\n",
      "2         9  chr1    12042026  12042171  GTF2F1   plus\n",
      "3        10  chr1    12081701  12081897  GTF2F1   plus\n",
      "4        11  chr1    15753645  15753780  GTF2F1   plus\n"
     ]
    }
   ],
   "source": [
    "print(including_pos_df.head())\n",
    "print(including_neg_df.head())\n",
    "\n",
    "including_df = pd.concat([including_pos_df, including_neg_df]).reset_index(drop=True)\n",
    "print(including_df.head())\n",
    "including_df.to_csv('including_df_bw_K562_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "positive-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "constitutive_pos_df = generate_data(rbp_dict, df_ex_con_pos, const=5000, strand='plus')\n",
    "constitutive_neg_df = generate_data(rbp_dict, df_ex_con_neg, const=5000, strand='minus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "balanced-variance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   exon_idx   chr  exon_start  exon_end     rbp strand\n",
      "0        10  chr1     1414428   1414488  GTF2F1   plus\n",
      "1        11  chr1     1453095   1453155  GTF2F1   plus\n",
      "2        12  chr1     1461840   1461911  GTF2F1   plus\n",
      "3        23  chr1     2333645   2333781  GTF2F1   plus\n",
      "4        32  chr1     6885151   6885270  GTF2F1   plus\n",
      "   exon_idx   chr  exon_start  exon_end     rbp strand\n",
      "0         0  chr1      880897    881033  GTF2F1  minus\n",
      "1         1  chr1      887791    887980  GTF2F1  minus\n",
      "2         2  chr1      892273    892405  GTF2F1  minus\n",
      "3         3  chr1     1153837   1154013  GTF2F1  minus\n",
      "4         4  chr1     1159211   1159348  GTF2F1  minus\n",
      "   exon_idx   chr  exon_start  exon_end     rbp strand\n",
      "0        10  chr1     1414428   1414488  GTF2F1   plus\n",
      "1        11  chr1     1453095   1453155  GTF2F1   plus\n",
      "2        12  chr1     1461840   1461911  GTF2F1   plus\n",
      "3        23  chr1     2333645   2333781  GTF2F1   plus\n",
      "4        32  chr1     6885151   6885270  GTF2F1   plus\n"
     ]
    }
   ],
   "source": [
    "print(constitutive_pos_df.head())\n",
    "print(constitutive_neg_df.head())\n",
    "\n",
    "constitutive_df = pd.concat([constitutive_pos_df, constitutive_neg_df]).reset_index(drop=True)\n",
    "print(constitutive_df.head())\n",
    "constitutive_df.to_csv('constitutive_df_bw_K562_filtered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-equipment",
   "metadata": {},
   "source": [
    "## Load the precomputed tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "authentic-arctic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   exon_idx   chr  exon_start  exon_end     rbp strand\n",
      "0         3  chr1    10166254  10166641  GTF2F1   plus\n",
      "1         4  chr1    11806183  11806280  GTF2F1   plus\n",
      "2         8  chr1    22400586  22400712  GTF2F1   plus\n",
      "3         9  chr1    26438950  26439141  GTF2F1   plus\n",
      "4        11  chr1    28857034  28857085  GTF2F1   plus\n"
     ]
    }
   ],
   "source": [
    "constitutive_df = pd.read_csv(\"constitutive_df_bw_K562_filtered.csv\", index_col=0)\n",
    "including_df = pd.read_csv(\"including_df_bw_K562_filtered.csv\", index_col=0)\n",
    "excluding_df = pd.read_csv(\"excluding_df_bw_K562_filtered.csv\", index_col=0)\n",
    "print(excluding_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "liberal-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(exon_rbp_df_raw, rbp_dict, const_raw=300, bin_size=30, filtered_chrs=[]):\n",
    "    const = (const_raw//bin_size)*bin_size\n",
    "    accepted_idx = []\n",
    "    exon_rbp_df = exon_rbp_df_raw[ ~exon_rbp_df_raw['chr'].isin(filtered_chrs)]\n",
    "    for idx, row in exon_rbp_df.iterrows():\n",
    "        chromosom = row['chr']\n",
    "        start = row['exon_start']\n",
    "        end = row['exon_end']\n",
    "        bw_cur = rbp_dict[row['rbp']][row['strand']]\n",
    "        chr_len = bw_cur.chroms()[chromosom]\n",
    "\n",
    "        start_pos = max(start-const, 0)\n",
    "        end_pos = min(end+const, chr_len-1)\n",
    "\n",
    "        intervals = bw_cur.intervals(chromosom, start_pos, end_pos)\n",
    "        if intervals is None:\n",
    "            continue\n",
    "        \n",
    "        accepted_idx.append(idx)\n",
    "        \n",
    "    print(len(accepted_idx))\n",
    "    final_df = exon_rbp_df.iloc[accepted_idx, :]\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-adventure",
   "metadata": {},
   "source": [
    "# If you want to recomputed the filtered data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "confirmed-china",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262568\n",
      "filtered constitutive:  262568 out of  282061\n",
      "46665\n",
      "filtered including:  46665 out of  46665\n",
      "13738\n",
      "filtered excluding:  13738 out of  13738\n",
      "{'NONO', 'U2AF2', 'TIA1', 'GEMIN5', 'RBM22', 'AQR', 'ILF3', 'SF3B1', 'QKI', 'PRPF8', 'SRSF7', 'FUS', 'HNRNPL', 'HNRNPC', 'TARDBP', 'PTBP1', 'PCBP1', 'HNRNPU', 'EFTUD2', 'UPF1', 'BUD13', 'HNRNPK', 'SF3B4', 'SRSF1', 'SMNDC1', 'TRA2A', 'ZRANB2', 'HNRNPM', 'KHSRP', 'U2AF1', 'RBFOX2', 'HNRNPA1', 'NCBP2', 'GTF2F1', 'LARP7', 'HNRNPUL1'}\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "filtered_constitutive_df = filter_data(constitutive_df, rbp_dict)\n",
    "print('filtered constitutive: ', len(filtered_constitutive_df), 'out of ', len(constitutive_df))\n",
    "filtered_including_df = filter_data(including_df, rbp_dict)\n",
    "print('filtered including: ', len(filtered_including_df), 'out of ', len(filtered_including_df))\n",
    "filtered_excluding_df = filter_data(excluding_df, rbp_dict)\n",
    "print('filtered excluding: ', len(filtered_excluding_df), 'out of ', len(filtered_excluding_df))\n",
    "\n",
    "common_rbps = set(filtered_constitutive_df['rbp']) & set(filtered_including_df['rbp']) & set(filtered_excluding_df['rbp'])\n",
    "print(common_rbps)\n",
    "print(len(common_rbps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "rental-brazil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   exon_idx   chr  exon_start  exon_end     rbp strand\n",
      "0         3  chr1    10166254  10166641  GTF2F1   plus\n",
      "1         4  chr1    11806183  11806280  GTF2F1   plus\n",
      "2         8  chr1    22400586  22400712  GTF2F1   plus\n",
      "3         9  chr1    26438950  26439141  GTF2F1   plus\n",
      "4        11  chr1    28857034  28857085  GTF2F1   plus\n"
     ]
    }
   ],
   "source": [
    "print(filtered_excluding_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-progressive",
   "metadata": {},
   "source": [
    "# Loading the pre-computed filtered files:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-compression",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "selected-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_pos = pd.concat([filtered_including_df, filtered_constitutive_df]).copy()\n",
    "filtered_pos = filtered_including_df.copy()\n",
    "filtered_neg = filtered_excluding_df.copy()\n",
    "filtered_pos['label'] = 1\n",
    "filtered_neg['label'] = 0\n",
    "all_data = pd.concat([filtered_pos, filtered_neg]).reset_index(drop=True)\n",
    "\n",
    "test_chrs = ['chr1']\n",
    "validation_chrs = ['chr3', 'chr2']\n",
    "validation_test_chrs = validation_chrs + test_chrs\n",
    "\n",
    "training_df = all_data[ ~all_data['chr'].isin(validation_test_chrs)]\n",
    "validation_df = all_data[ all_data['chr'].isin(validation_chrs)]\n",
    "test_df = all_data[ all_data['chr'].isin(test_chrs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "respiratory-ceremony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaning rbps:  36 out of  36\n",
      "train data:  44922\n",
      "validation data:  7902\n",
      "test data:  7579\n",
      "    exon_idx    chr  exon_start  exon_end     rbp strand  label\n",
      "81       175  chr10     5777266   5777509  GTF2F1   plus      1\n",
      "82       178  chr10    13655740  13655881  GTF2F1   plus      1\n",
      "83       179  chr10    14893217  14893322  GTF2F1   plus      1\n",
      "84       181  chr10    18961550  18961634  GTF2F1   plus      1\n",
      "85       186  chr10    28884661  28884970  GTF2F1   plus      1\n"
     ]
    }
   ],
   "source": [
    "remaining_rbps = set(training_df['rbp']) & set(validation_df['rbp']) & set(test_df['rbp'])\n",
    "print('remaning rbps: ', len(remaining_rbps), 'out of ', len(rbp_dict))\n",
    "\n",
    "training_data = training_df[ training_df['rbp'].isin(remaining_rbps)]\n",
    "validation_data = validation_df[ validation_df['rbp'].isin(remaining_rbps)]\n",
    "test_data = test_df[ test_df['rbp'].isin(remaining_rbps)]\n",
    "\n",
    "print('train data: ', len(training_data))\n",
    "print('validation data: ', len(validation_data))\n",
    "print('test data: ', len(test_data))\n",
    "print(training_data.head())\n",
    "\n",
    "remaining_rbps_dict = {}\n",
    "rbps_list = sorted(list(remaining_rbps))\n",
    "for i in range(len(rbps_list)):\n",
    "    remaining_rbps_dict[rbps_list[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "elect-comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7]\n",
      "[[3 2 1]\n",
      " [6 5 4]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array(range(8))\n",
    "print(a)\n",
    "a[-3:-1]\n",
    "b = np.array([[1,2,3],[4,5,6]])\n",
    "b = np.flip(b, axis=1)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "wicked-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "def generate_vectors(exon_rbp_df, rbps_to_int_dict, rbp_dict, const=300, bin_size=20, w_inside=5):\n",
    "    X = []\n",
    "    y = []\n",
    "    srt_df = exon_rbp_df.sort_values(by='exon_idx')\n",
    "    gr_df = srt_df.groupby(by='exon_idx')\n",
    "    \n",
    "    sec_len = const//bin_size\n",
    "    vec_len = (const//bin_size)*2 + w_inside\n",
    "    \n",
    "    for exon_idx, neigh_rbf_df in gr_df:\n",
    "        left_vec_rep = np.zeros((len(rbps_to_int_dict), sec_len))\n",
    "        right_vec_rep = np.zeros((len(rbps_to_int_dict), sec_len))\n",
    "        mid_vec_rep = np.zeros((len(rbps_to_int_dict), w_inside))\n",
    "        for idx, row in neigh_rbf_df.iterrows():\n",
    "            # print('-----------------')\n",
    "            # print('row:', row)\n",
    "            cur_rbp = rbps_to_int_dict[row['rbp']]\n",
    "            cur_bw = rbp_dict[row['rbp']][row['strand']]\n",
    "            # print('rbp number:', cur_rbp)\n",
    "            chromosom = row['chr']\n",
    "            start = row['exon_start']\n",
    "            end = row['exon_end']\n",
    "            chr_len = cur_bw.chroms()[chromosom]\n",
    "\n",
    "            l_start_pos = max(start-const, 0)\n",
    "            l_end_pos = min(start, chr_len-1)\n",
    "\n",
    "            # l_intervals = cur_rbp.intervals(chromosom, l_start_pos, l_end_pos)\n",
    "            # if l_intervals is None:\n",
    "            #     l_intervals = []\n",
    "                \n",
    "            r_start_pos = max(end, 0)\n",
    "            r_end_pos = min(end+const, chr_len-1)\n",
    "\n",
    "            # r_intervals = cur_rbp.intervals(chromosom, r_start_pos, r_end_pos)\n",
    "            # if r_intervals is None:\n",
    "            #     r_intervals = []\n",
    "                 \n",
    "            values_left = np.array(cur_bw.stats(chromosom, l_start_pos, l_end_pos, nBins=sec_len))\n",
    "            values_left[values_left == None] = 0.\n",
    "            left_vec_rep[cur_rbp, :] = values_left.astype(float, copy=False)\n",
    "\n",
    "            values_right = np.array(cur_bw.stats(chromosom, r_start_pos, r_end_pos, nBins=sec_len))\n",
    "            values_right[values_right == None] = 0.\n",
    "            right_vec_rep[cur_rbp, :] = values_right.astype(float, copy=False)\n",
    "        \n",
    "            values_middle = np.array(cur_bw.stats(chromosom, start, end, nBins=w_inside))\n",
    "            values_middle[values_middle == None] = 0.\n",
    "            mid_vec_rep[cur_rbp, :] = values_middle.astype(float, copy=False)                \n",
    "\n",
    "        \n",
    "        new_data_point = np.concatenate([left_vec_rep, mid_vec_rep, right_vec_rep], axis=1)\n",
    "        if row['strand'] == 'minus':\n",
    "            new_data_point = np.flip(new_data_point, axis=1)\n",
    "        X.append(new_data_point)\n",
    "        y.append(int(row['label']))\n",
    "                \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "israeli-gather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174, 36, 25)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = generate_vectors(training_data, remaining_rbps_dict, rbp_dict, const=300, bin_size=30, w_inside=5)\n",
    "\n",
    "# for i in range(len(X_train[0])):\n",
    "#     print(i, list(X_train[0][i]))\n",
    "\n",
    "X_val, y_val = generate_vectors(validation_data, remaining_rbps_dict, rbp_dict, const=300, bin_size=30, w_inside=5)\n",
    "X_test, y_test = generate_vectors(test_data, remaining_rbps_dict, rbp_dict, const=300, bin_size=30, w_inside=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "subjective-synthesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174, 36, 25)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "electric-floating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:  (1208, 36, 25)\n",
      "after:  (1208, 900)\n",
      "test: (174, 900)\n",
      "(1458, 900)\n",
      "(1458,)\n",
      "pos tr/val:  1182 from:  1458\n",
      "pos test:  139 from:  174\n",
      "(1458, 901)\n",
      "(1458, 900)\n",
      "(1458,)\n"
     ]
    }
   ],
   "source": [
    "### Making the data 1-dimensional:\n",
    "\n",
    "# for i in range(len(X_train[0])):\n",
    "#     print(i, list(X_train[0][i]))\n",
    "\n",
    "print('before: ', X_train.shape)\n",
    "X_train_1d = np.reshape(X_train, (X_train.shape[0],-1)) \n",
    "print('after: ', X_train_1d.shape)\n",
    "# print(list(X_train_1d[0]))\n",
    "\n",
    "X_val_1d = np.reshape(X_val, (X_val.shape[0],-1)) \n",
    "X_test_1d = np.reshape(X_test, (X_test.shape[0],-1)) \n",
    "print('test:', X_test_1d.shape)\n",
    "\n",
    "X_train_val_1d = np.concatenate([X_train_1d, X_val_1d])\n",
    "print(X_train_val_1d.shape)\n",
    "y_train_val = np.concatenate([y_train, y_val])\n",
    "print(y_train_val.shape)\n",
    "\n",
    "print('pos tr/val: ', np.sum(y_train_val), 'from: ', len(y_train_val))\n",
    "print('pos test: ', np.sum(y_test), 'from: ', len(y_test))\n",
    "\n",
    "X_y_train_val = np.concatenate([X_train_val_1d, y_train_val.reshape(-1,1)], axis=1)\n",
    "print(X_y_train_val.shape)\n",
    "\n",
    "import random\n",
    "random.shuffle(X_y_train_val)\n",
    "X_train_val_1d = X_y_train_val[:,:-1]\n",
    "y_train_val = X_y_train_val[:,-1]\n",
    "print(X_train_val_1d.shape)\n",
    "print(y_train_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "incident-roller",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.874):\n",
      "{'svm__C': 1, 'svm__kernel': 'linear'}\n",
      "0.6494252873563219\n",
      "[0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0.\n",
      " 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1.]\n",
      "[1 0 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 0 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "param_grid = {\n",
    "    'svm__kernel': ['linear'],\n",
    "    'svm__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "}\n",
    "\n",
    "svm_module = svm.SVC(tol=0.01, class_weight='balanced')\n",
    "standardScaler = StandardScaler()\n",
    "pipe = Pipeline(steps=[('standard', standardScaler), ('svm', svm_module)])\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=14)\n",
    "search.fit(X_train_val_1d, y_train_val)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n",
    "\n",
    "print(search.score(X_test_1d, y_test))\n",
    "print(search.predict(X_test_1d))\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eligible-visibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.782):\n",
      "{'logistic__C': 46.41588833612782, 'pca__n_components': 256}\n",
      "0.5862068965517241\n",
      "[0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0.\n",
      " 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1.\n",
      " 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'pca__n_components': [5, 15, 30, 45, 64, 75, 128, 256],\n",
    "    'logistic__C': np.logspace(-5, 5, 10),\n",
    "}\n",
    "\n",
    "pca = PCA()\n",
    "logistic = LogisticRegression(max_iter=10000, tol=0.1, class_weight='balanced')\n",
    "pipe = Pipeline(steps=[('pca', pca), ('logistic', logistic)])\n",
    "\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=14)\n",
    "search.fit(X_train_val_1d, y_train_val)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n",
    "\n",
    "print(search.score(X_test_1d, y_test))\n",
    "\n",
    "print(search.predict(X_test_1d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "integral-preparation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.861):\n",
      "{'pca__n_components': 512, 'svm__C': 1, 'svm__kernel': 'linear'}\n",
      "0.6494252873563219\n",
      "[1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "param_grid = {\n",
    "    'pca__n_components': [8, 16, 32, 64, 128, 256, 512],\n",
    "    'svm__kernel': ['linear'],\n",
    "    'svm__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    # 'svm__gamma': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "}\n",
    "\n",
    "standardScaler = StandardScaler()\n",
    "pca = PCA()\n",
    "svm_module = svm.SVC(tol=0.01, class_weight='balanced')\n",
    "pipe = Pipeline(steps=[('pca', pca), ('svm', svm_module)])\n",
    "\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=14)\n",
    "search.fit(X_train_val_1d, y_train_val)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n",
    "\n",
    "print(search.score(X_test_1d, y_test))\n",
    "\n",
    "print(search.predict(X_test_1d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "welcome-chapter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6494252873563219\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean( (search.predict(X_test_1d) > .5) == (y_test > .5))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-chase",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "alleged-pipeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.8.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.0486)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "assert(torch.cuda.is_available()) # if this fails go to Runtime -> Change runtime type -> Set \"Hardware Accelerator\"\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "nn.functional.softplus(torch.tensor(3.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "eligible-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BWVecDataset(torch.utils.data.IterableDataset):\n",
    "\n",
    "    def __init__(self, exon_rbp_df, rbps_to_int_dict, rbp_dict, const=300, bin_size=20, w_inside=5):\n",
    "        super(BWVecDataset, self).__init__()\n",
    "        self.exon_rbp_df = exon_rbp_df\n",
    "        self.rbps_to_int_dict = rbps_to_int_dict\n",
    "        self.rbp_dict = rbp_dict\n",
    "        self.const = const\n",
    "        self.bin_size = bin_size\n",
    "        self.w_inside = w_inside\n",
    "\n",
    "    def __iter__(self): \n",
    "        srt_df = self.exon_rbp_df.sort_values(by='exon_idx')\n",
    "        gr_df = srt_df.groupby(by='exon_idx')\n",
    "    \n",
    "        sec_len = self.const//self.bin_size\n",
    "        vec_len = (self.const//self.bin_size)*2 + self.w_inside\n",
    "        for exon_idx, neigh_rbf_df in gr_df:\n",
    "            left_vec_rep = np.zeros((len(self.rbps_to_int_dict), sec_len))\n",
    "            right_vec_rep = np.zeros((len(self.rbps_to_int_dict), sec_len))\n",
    "            mid_vec_rep = np.zeros((len(self.rbps_to_int_dict), self.w_inside))\n",
    "            for idx, row in neigh_rbf_df.iterrows():\n",
    "                cur_rbp = self.rbps_to_int_dict[row['rbp']]\n",
    "                cur_bw = self.rbp_dict[row['rbp']][row['strand']]\n",
    "\n",
    "                chromosom = row['chr']\n",
    "                start = row['exon_start']\n",
    "                end = row['exon_end']\n",
    "                chr_len = cur_bw.chroms()[chromosom]\n",
    "\n",
    "                l_start_pos = max(start-self.const, 0)\n",
    "                l_end_pos = min(start, chr_len-1)\n",
    "\n",
    "                r_start_pos = max(end, 0)\n",
    "                r_end_pos = min(end+self.const, chr_len-1)\n",
    "\n",
    "                values_left = np.array(cur_bw.stats(chromosom, l_start_pos, l_end_pos, nBins=sec_len))\n",
    "                values_left[values_left == None] = 0.\n",
    "                left_vec_rep[cur_rbp, :] = values_left.astype(float, copy=False)\n",
    "\n",
    "                values_right = np.array(cur_bw.stats(chromosom, r_start_pos, r_end_pos, nBins=sec_len))\n",
    "                values_right[values_right == None] = 0.\n",
    "                right_vec_rep[cur_rbp, :] = values_right.astype(float, copy=False)\n",
    "\n",
    "                values_middle = np.array(cur_bw.stats(chromosom, start, end, nBins=self.w_inside))\n",
    "                values_middle[values_middle == None] = 0.\n",
    "                mid_vec_rep[cur_rbp, :] = values_middle.astype(float, copy=False)                \n",
    "\n",
    "\n",
    "            new_data_point = np.concatenate([left_vec_rep, mid_vec_rep, right_vec_rep], axis=1)\n",
    "            if row['strand'] == 'minus':\n",
    "                new_data_point = np.flip(new_data_point, axis=1)\n",
    "            \n",
    "            yield torch.from_numpy(new_data_point.copy()), torch.tensor(int(row['label'])) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "quiet-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreDataset(torch.utils.data.IterableDataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        super(PreDataset, self).__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __iter__(self): \n",
    "        for idx, sample in enumerate(self.X):\n",
    "            yield torch.from_numpy(sample.copy()), torch.tensor(int(self.y[idx])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "occupational-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BWVecDataset(training_data, remaining_rbps_dict, rbp_dict, const=300, bin_size=30, w_inside=5)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, num_workers=8)\n",
    "\n",
    "validation_dataset = BWVecDataset(validation_data, remaining_rbps_dict, rbp_dict, const=300, bin_size=30, w_inside=5)\n",
    "validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=64, num_workers=8)\n",
    "\n",
    "test_dataset = BWVecDataset(test_data, remaining_rbps_dict, rbp_dict, const=300, bin_size=30, w_inside=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=256, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "sweet-prince",
   "metadata": {},
   "outputs": [],
   "source": [
    "simp_train_dataset = PreDataset(X_train, y_train)\n",
    "simp_train_dataloader = torch.utils.data.DataLoader(simp_train_dataset, batch_size=64, num_workers=0)\n",
    "\n",
    "simp_validation_dataset = PreDataset(X_val, y_val)\n",
    "simp_validation_dataloader = torch.utils.data.DataLoader(simp_validation_dataset, batch_size=64, num_workers=0)\n",
    "\n",
    "simp_test_dataset = PreDataset(X_test, y_test)\n",
    "simp_test_dataloader = torch.utils.data.DataLoader(simp_test_dataset, batch_size=8, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "local-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_epoch(train_flag, dataloader, model, optimizer, device=\"cuda\"):\n",
    "\n",
    "    torch.set_grad_enabled(train_flag)\n",
    "    model.train() if train_flag else model.eval() \n",
    "\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    APs = []\n",
    "\n",
    "    for (x,y) in dataloader: \n",
    "\n",
    "        (x, y) = ( x.to(device).float(), y.to(device).float() )\n",
    "        x = torch.transpose(x, 1,2)\n",
    "        output = model(x)\n",
    "        output = output.squeeze() \n",
    "        loss = F.binary_cross_entropy_with_logits( output, y )\n",
    "        # loss = nn.functional.mse_loss(output, y )\n",
    "\n",
    "        if train_flag: \n",
    "            loss.backward() # back propagation\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        accuracy = torch.mean( ( (output > .5) == (y > .5) ).float() )\n",
    "        accuracies.append(accuracy.detach().cpu().numpy())  \n",
    "    \n",
    "        AP = average_precision_score(y.detach().cpu().numpy(), output.detach().cpu().numpy())\n",
    "        AP=0.0\n",
    "        APs.append(AP)\n",
    "    \n",
    "    return( np.mean(losses), np.mean(accuracies) , np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "absolute-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def run_one_weighted_epoch(train_flag, dataloader, model, optimizer, device=\"cuda\"):\n",
    "\n",
    "    torch.set_grad_enabled(train_flag)\n",
    "    model.train() if train_flag else model.eval() \n",
    "\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    APs = []\n",
    "    counter = 0\n",
    "    for (x,y) in dataloader: # collection of tuples with iterator\n",
    "        \n",
    "        pos_neg_ratio = y.sum()/len(y)\n",
    "        weight_ratio = 1. - 2*pos_neg_ratio\n",
    "        weights_vec = (y * weight_ratio) + pos_neg_ratio\n",
    "            \n",
    "        (x, y) = ( x.to(device), y.to(device) ) # transfer data to GPU\n",
    "        x = torch.transpose(x, 1,2)\n",
    "        weights_vec = weights_vec.to(device)\n",
    "\n",
    "        output = model(x) # forward pass\n",
    "        output = output.squeeze() # remove spurious channel dimension        \n",
    "        loss = F.binary_cross_entropy_with_logits(output, y, weight=weights_vec) # numerically stable\n",
    "\n",
    "        if train_flag: \n",
    "            loss.backward() # back propagation\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        accuracy = torch.mean( ( (output > .5) == (y > .5) ).float() )\n",
    "        accuracies.append(accuracy.detach().cpu().numpy())  \n",
    "        \n",
    "        AP = average_precision_score(y.detach().cpu().numpy(), output.detach().cpu().numpy())\n",
    "        APs.append(AP)\n",
    "    \n",
    "    return( np.mean(losses), np.mean(accuracies) , np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "controversial-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "def train_skewed_rc_model(model, train_dataloader, validation_dataloader, epochs=100, patience=10, verbose=True, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Train a 1D CNN model and record accuracy metrics.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5, amsgrad=True)\n",
    "\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    patience_counter = patience\n",
    "    train_loss_all = []\n",
    "    val_loss_all = []\n",
    "    val_aps_all = []\n",
    "    best_val_loss = np.inf\n",
    "    check_point_filename = 'model_checkpoint.pt'\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start_time = timeit.default_timer()\n",
    "        train_loss, train_acc, train_aps = run_one_epoch(True, train_dataloader, model, optimizer, device)\n",
    "        val_loss, val_acc, val_aps = run_one_epoch(False, validation_dataloader, model, optimizer, device)\n",
    "        # train_loss, train_acc, train_aps = run_one_weighted_epoch(True, train_dataloader, model, optimizer, device)\n",
    "        # val_loss, val_acc, val_aps = run_one_rc_epoch(validation_dataloader, model, optimizer, device)\n",
    "        \n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        train_loss_all.append(train_loss)\n",
    "        val_loss_all.append(val_loss)\n",
    "        val_aps_all.append(val_aps)\n",
    "        if val_loss < best_val_loss: \n",
    "            torch.save(model.state_dict(), check_point_filename)\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = patience\n",
    "        else: \n",
    "            patience_counter -= 1\n",
    "            if patience_counter <= 0: \n",
    "                break\n",
    "        elapsed = float(timeit.default_timer() - start_time)\n",
    "        if verbose:\n",
    "            print(\"Epoch %i took %.2fs. Train loss: %.4f acc: %.4f. Val loss: %.4f acc: %.4f aps: %.4f. Patience left: %i\" % \n",
    "                  (epoch+1, elapsed, train_loss, train_acc, val_loss, val_acc, val_aps, patience_counter ))\n",
    "\n",
    "    model.load_state_dict(torch.load(check_point_filename)) # recover the best model so far\n",
    "\n",
    "    return model, train_accs, val_accs, train_loss_all, val_loss_all, val_aps_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "third-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "australian-abraham",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-294-b5722be2ac87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cth/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cth/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cth/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-248-1a316e2ef74a>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mr_end_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchr_len\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mvalues_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_bw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchromosom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_start_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_end_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnBins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msec_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0mvalues_left\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mleft_vec_rep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_rbp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues_left\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for (x,y) in train_dataloader:\n",
    "    x=torch.transpose(x, 1,2)\n",
    "    x=torch.transpose(x, 0,1).float()\n",
    "    print(x.shape)\n",
    "    print(y)\n",
    "    ln = nn.Linear(36, 10)\n",
    "    mdl = torch.nn.MultiheadAttention(36, 1, dropout=0.0, bias=True, add_bias_kv=False, add_zero_attn=False, kdim=None, vdim=None)\n",
    "    out = mdl(x.float(), x.float(), x.float())\n",
    "    # out = mdl(x.float(), x.float(), torch.transpose(ln(torch.transpose(x, 0,1)), 0, 1).float())\n",
    "    print(out[0].shape)\n",
    "    counter += 1\n",
    "    if counter > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "eight-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 feature_dim = 36,\n",
    "                 embed_dim = 10,\n",
    "                 mid_dim = 16,\n",
    "                 dropout = 0.2):\n",
    "        \n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.feature_dim = feature_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.mid_dim = mid_dim\n",
    "        self.drop2d = nn.Dropout2d(dropout)\n",
    "        self.q_linear = nn.Linear(feature_dim, mid_dim)\n",
    "        self.k_linear = nn.Linear(feature_dim, mid_dim)\n",
    "        self.v_linear = nn.Linear(feature_dim, embed_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print('x: ', x.shape)\n",
    "        q = self.q_linear(x)\n",
    "        # print('q: ', q.shape)\n",
    "        k = self.k_linear(x)\n",
    "        v = self.v_linear(x)\n",
    "        \n",
    "        scale = self.mid_dim ** 0.5\n",
    "        softmax = F.softmax((q.bmm(k.transpose(1, 2))) / scale, dim=-1)\n",
    "        return softmax.bmm(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "quality-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_heads = 8, \n",
    "                 feature_dim = 36, \n",
    "                 embed_dim = 10, \n",
    "                 mid_dim = 16,\n",
    "                 dropout = 0.2,\n",
    "                 mha_out_dim = 1):\n",
    "        \n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        \n",
    "        self.heads_list = nn.ModuleList(\n",
    "            [Attention(feature_dim=feature_dim, embed_dim=embed_dim, mid_dim=mid_dim) for _ in range(num_heads)]\n",
    "        )\n",
    "        self.linear = nn.Linear(num_heads * embed_dim, mha_out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.cat([head(x) for head in self.heads_list], dim=-1)\n",
    "        h = self.linear(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "middle-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 seq_len = 25,\n",
    "                 num_heads = 8, \n",
    "                 feature_dim = 36, \n",
    "                 embed_dim = 10, \n",
    "                 mid_dim = 16,\n",
    "                 dropout = 0.2,\n",
    "                 mha_out_dim = 1,\n",
    "                 hidden = 8):\n",
    "\n",
    "        super(MyModel, self).__init__()\n",
    "    \n",
    "        self.mha = MultiHeadAttention(num_heads = 8, \n",
    "                                     feature_dim = 36, \n",
    "                                     embed_dim = 10, \n",
    "                                     mid_dim = 16,\n",
    "                                     dropout = 0.2,\n",
    "                                     mha_out_dim = 1)\n",
    "    \n",
    "        self.linear = nn.Linear(seq_len, hidden)\n",
    "        self.result = nn.Linear(hidden, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.mha(x)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(torch.transpose(h,-2,-1))\n",
    "        h = F.relu(h)\n",
    "        h = self.result(h)\n",
    "        return h.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for (x,y) in train_dataloader:\n",
    "    x = torch.transpose(x, 1,2).float()\n",
    "    print(x.shape)\n",
    "    print(y)\n",
    "    mdl = MyModel()\n",
    "    out = mdl(x)\n",
    "    # print(out[0].shape)\n",
    "    print(out)\n",
    "    counter += 1\n",
    "    if counter > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "silent-equity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 took 0.33s. Train loss: 0.6991 acc: 0.1711. Val loss: 0.6794 acc: 0.2656 aps: 0.0000. Patience left: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 took 0.30s. Train loss: 0.6651 acc: 0.1711. Val loss: 0.6709 acc: 0.2656 aps: 0.0000. Patience left: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 took 0.29s. Train loss: 0.6556 acc: 0.1711. Val loss: 0.6651 acc: 0.2656 aps: 0.0000. Patience left: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 took 0.30s. Train loss: 0.6468 acc: 0.1719. Val loss: 0.6593 acc: 0.2656 aps: 0.0000. Patience left: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 took 0.30s. Train loss: 0.6376 acc: 0.1727. Val loss: 0.6529 acc: 0.2656 aps: 0.0000. Patience left: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 took 0.29s. Train loss: 0.6252 acc: 0.1743. Val loss: 0.6425 acc: 0.2617 aps: 0.0000. Patience left: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 took 0.29s. Train loss: 0.5934 acc: 0.2566. Val loss: 0.6240 acc: 0.4609 aps: 0.0000. Patience left: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 took 0.30s. Train loss: 0.5614 acc: 0.4669. Val loss: 0.6268 acc: 0.5197 aps: 0.0000. Patience left: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 took 0.30s. Train loss: 0.5577 acc: 0.4927. Val loss: 0.6206 acc: 0.5119 aps: 0.0000. Patience left: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 took 0.32s. Train loss: 0.5434 acc: 0.4952. Val loss: 0.6140 acc: 0.5205 aps: 0.0000. Patience left: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 took 0.29s. Train loss: 0.5289 acc: 0.5332. Val loss: 0.6089 acc: 0.5490 aps: 0.0000. Patience left: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 took 0.30s. Train loss: 0.5131 acc: 0.6503. Val loss: 0.5986 acc: 0.6538 aps: 0.0000. Patience left: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 took 0.30s. Train loss: 0.4776 acc: 0.7984. Val loss: 0.5914 acc: 0.7422 aps: 0.0000. Patience left: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 took 0.29s. Train loss: 0.4523 acc: 0.8314. Val loss: 0.6105 acc: 0.7383 aps: 0.0000. Patience left: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 took 0.29s. Train loss: 0.4433 acc: 0.8339. Val loss: 0.6253 acc: 0.7383 aps: 0.0000. Patience left: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 took 0.30s. Train loss: 0.4441 acc: 0.8355. Val loss: 0.6333 acc: 0.7383 aps: 0.0000. Patience left: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 took 0.29s. Train loss: 0.4420 acc: 0.8355. Val loss: 0.6390 acc: 0.7383 aps: 0.0000. Patience left: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 took 0.31s. Train loss: 0.4385 acc: 0.8339. Val loss: 0.6444 acc: 0.7383 aps: 0.0000. Patience left: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 took 0.29s. Train loss: 0.4352 acc: 0.8380. Val loss: 0.6491 acc: 0.7383 aps: 0.0000. Patience left: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 took 0.28s. Train loss: 0.4321 acc: 0.8405. Val loss: 0.6525 acc: 0.7383 aps: 0.0000. Patience left: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 took 0.32s. Train loss: 0.4306 acc: 0.8413. Val loss: 0.6566 acc: 0.7383 aps: 0.0000. Patience left: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 took 0.29s. Train loss: 0.4279 acc: 0.8413. Val loss: 0.6611 acc: 0.7383 aps: 0.0000. Patience left: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/aebrahimpour/.conda/envs/cth/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(MyModel(\n",
       "   (mha): MultiHeadAttention(\n",
       "     (heads_list): ModuleList(\n",
       "       (0): Attention(\n",
       "         (drop2d): Dropout2d(p=0.2, inplace=False)\n",
       "         (q_linear): Linear(in_features=36, out_features=16, bias=True)\n",
       "         (k_linear): Linear(in_features=36, out_features=16, bias=True)\n",
       "         (v_linear): Linear(in_features=36, out_features=10, bias=True)\n",
       "       )\n",
       "       (1): Attention(\n",
       "         (drop2d): Dropout2d(p=0.2, inplace=False)\n",
       "         (q_linear): Linear(in_features=36, out_features=16, bias=True)\n",
       "         (k_linear): Linear(in_features=36, out_features=16, bias=True)\n",
       "         (v_linear): Linear(in_features=36, out_features=10, bias=True)\n",
       "       )\n",
       "       (2): Attention(\n",
       "         (drop2d): Dropout2d(p=0.2, inplace=False)\n",
       "         (q_linear): Linear(in_features=36, out_features=16, bias=True)\n",
       "         (k_linear): Linear(in_features=36, out_features=16, bias=True)\n",
       "         (v_linear): Linear(in_features=36, out_features=10, bias=True)\n",
       "       )\n",
       "       (3): Attention(\n",
       "         (drop2d): Dropout2d(p=0.2, inplace=False)\n",
       "         (q_linear): Linear(in_features=36, out_features=16, bias=True)\n",
       "         (k_linear): Linear(in_features=36, out_features=16, bias=True)\n",
       "         (v_linear): Linear(in_features=36, out_features=10, bias=True)\n",
       "       )\n",
       "       (4): Attention(\n",
       "         (drop2d): Dropout2d(p=0.2, inplace=False)\n",
       "         (q_linear): Linear(in_features=36, out_features=16, bias=True)\n",
       "         (k_linear): Linear(in_features=36, out_features=16, bias=True)\n",
       "         (v_linear): Linear(in_features=36, out_features=10, bias=True)\n",
       "       )\n",
       "       (5): Attention(\n",
       "         (drop2d): Dropout2d(p=0.2, inplace=False)\n",
       "         (q_linear): Linear(in_features=36, out_features=16, bias=True)\n",
       "         (k_linear): Linear(in_features=36, out_features=16, bias=True)\n",
       "         (v_linear): Linear(in_features=36, out_features=10, bias=True)\n",
       "       )\n",
       "       (6): Attention(\n",
       "         (drop2d): Dropout2d(p=0.2, inplace=False)\n",
       "         (q_linear): Linear(in_features=36, out_features=16, bias=True)\n",
       "         (k_linear): Linear(in_features=36, out_features=16, bias=True)\n",
       "         (v_linear): Linear(in_features=36, out_features=10, bias=True)\n",
       "       )\n",
       "       (7): Attention(\n",
       "         (drop2d): Dropout2d(p=0.2, inplace=False)\n",
       "         (q_linear): Linear(in_features=36, out_features=16, bias=True)\n",
       "         (k_linear): Linear(in_features=36, out_features=16, bias=True)\n",
       "         (v_linear): Linear(in_features=36, out_features=10, bias=True)\n",
       "       )\n",
       "     )\n",
       "     (linear): Linear(in_features=80, out_features=1, bias=True)\n",
       "   )\n",
       "   (linear): Linear(in_features=25, out_features=8, bias=True)\n",
       "   (result): Linear(in_features=8, out_features=1, bias=True)\n",
       " ),\n",
       " [0.17105263,\n",
       "  0.17105263,\n",
       "  0.17105263,\n",
       "  0.171875,\n",
       "  0.17269737,\n",
       "  0.17434211,\n",
       "  0.25657895,\n",
       "  0.4668703,\n",
       "  0.4927162,\n",
       "  0.4951833,\n",
       "  0.5332472,\n",
       "  0.6502585,\n",
       "  0.7984023,\n",
       "  0.83141446,\n",
       "  0.83388156,\n",
       "  0.8355263,\n",
       "  0.8355263,\n",
       "  0.83388156,\n",
       "  0.83799344,\n",
       "  0.84046054,\n",
       "  0.8412829,\n",
       "  0.8412829,\n",
       "  0.84375],\n",
       " [0.265625,\n",
       "  0.265625,\n",
       "  0.265625,\n",
       "  0.265625,\n",
       "  0.265625,\n",
       "  0.26171875,\n",
       "  0.4609375,\n",
       "  0.51966596,\n",
       "  0.51185346,\n",
       "  0.52047414,\n",
       "  0.5490302,\n",
       "  0.6538254,\n",
       "  0.7421875,\n",
       "  0.73828125,\n",
       "  0.73828125,\n",
       "  0.73828125,\n",
       "  0.73828125,\n",
       "  0.73828125,\n",
       "  0.73828125,\n",
       "  0.73828125,\n",
       "  0.73828125,\n",
       "  0.73828125,\n",
       "  0.73828125],\n",
       " [0.69907206,\n",
       "  0.6650551,\n",
       "  0.6556086,\n",
       "  0.64684355,\n",
       "  0.63756204,\n",
       "  0.62517244,\n",
       "  0.59343314,\n",
       "  0.56141835,\n",
       "  0.55771244,\n",
       "  0.5433857,\n",
       "  0.5289232,\n",
       "  0.5130947,\n",
       "  0.47763735,\n",
       "  0.45233807,\n",
       "  0.44327775,\n",
       "  0.4440703,\n",
       "  0.44203788,\n",
       "  0.43845406,\n",
       "  0.4351737,\n",
       "  0.4321003,\n",
       "  0.43056327,\n",
       "  0.42794093,\n",
       "  0.42537072],\n",
       " [0.679356,\n",
       "  0.670858,\n",
       "  0.66510177,\n",
       "  0.65929043,\n",
       "  0.6529432,\n",
       "  0.6424933,\n",
       "  0.6240066,\n",
       "  0.62678707,\n",
       "  0.6206364,\n",
       "  0.61395454,\n",
       "  0.6089116,\n",
       "  0.5986367,\n",
       "  0.5914132,\n",
       "  0.6105478,\n",
       "  0.6252971,\n",
       "  0.63334507,\n",
       "  0.6390106,\n",
       "  0.6443709,\n",
       "  0.64908165,\n",
       "  0.65245515,\n",
       "  0.6565513,\n",
       "  0.6611437,\n",
       "  0.6674937],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = MyModel()\n",
    "train_skewed_rc_model(my_model, simp_train_dataloader, simp_validation_dataloader, epochs=100, patience=10, verbose=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "upset-debate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5379417 0.78409094 0.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_aps = run_one_epoch(False, simp_test_dataloader, my_model, _, device)\n",
    "print(test_loss, test_acc, test_aps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "judicial-industry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "139\n",
      "tensor([1, 0, 0, 1, 0, 0, 0, 0])\n",
      "tensor([0.6816, 0.8121, 0.8055, 0.8017, 0.8100, 0.7937, 0.7881, 0.7641],\n",
      "       device='cuda:0')\n",
      "tensor([1, 0, 1, 1, 0, 1, 1, 0])\n",
      "tensor([0.7687, 0.7715, 0.7348, 0.7883, 0.8298, 0.8527, 0.7177, 0.8028],\n",
      "       device='cuda:0')\n",
      "tensor([1, 1, 0, 0, 0, 0, 1, 0])\n",
      "tensor([0.7243, 0.7518, 0.8084, 0.9075, 0.7947, 0.7602, 0.7860, 0.7962],\n",
      "       device='cuda:0')\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0.7258, 0.9742, 0.8323, 0.7550, 0.7579, 0.8736, 0.7590, 0.7897],\n",
      "       device='cuda:0')\n",
      "tensor([0, 1, 1, 1, 1, 0, 0, 1])\n",
      "tensor([0.7700, 0.8116, 0.7728, 0.8354, 0.7728, 0.7751, 0.8050, 0.7838],\n",
      "       device='cuda:0')\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 1])\n",
      "tensor([0.7989, 0.8833, 0.8172, 0.7670, 0.7871, 0.5939, 0.7242, 0.7583],\n",
      "       device='cuda:0')\n",
      "tensor([1, 0, 1, 0, 0, 0, 0, 1])\n",
      "tensor([0.7881, 0.7883, 0.7931, 0.7960, 0.7550, 0.7845, 0.7898, 0.8366],\n",
      "       device='cuda:0')\n",
      "tensor([0, 0, 1, 1, 1, 1, 1, 1])\n",
      "tensor([0.8267, 0.8353, 0.8217, 0.7793, 0.7921, 0.7863, 0.7929, 0.7818],\n",
      "       device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([0.7813, 0.7881, 0.8230, 0.7671, 0.7722, 0.7886, 0.7372, 0.7853],\n",
      "       device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([0.6756, 0.7578, 0.7851, 0.8453, 0.7881, 0.7746, 0.7425, 0.7756],\n",
      "       device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([0.7748, 0.7888, 0.7797, 0.7775, 0.7994, 0.7855, 0.7819, 0.7829],\n",
      "       device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([0.7740, 0.7876, 0.7786, 0.7576, 0.5999, 0.7969, 0.6696, 0.7753],\n",
      "       device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([0.7824, 0.7888, 0.7651, 0.8123, 0.7800, 0.7660, 0.7505, 0.7477],\n",
      "       device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([0.7966, 0.8466, 0.7832, 0.7451, 0.6239, 0.7841, 0.8013, 0.6862],\n",
      "       device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([0.7943, 0.7743, 0.7798, 0.7861, 0.7851, 0.6988, 0.7669, 0.9550],\n",
      "       device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([0.7884, 0.7887, 0.7920, 0.7883, 0.7793, 0.8529, 0.7755, 0.7827],\n",
      "       device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([0.7842, 0.7970, 0.8173, 0.8144, 0.8103, 0.8107, 0.7981, 0.8248],\n",
      "       device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([0.7497, 0.9945, 0.7699, 0.8268, 0.7611, 0.7843, 0.7728, 0.7824],\n",
      "       device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([0.7680, 0.7887, 0.8240, 0.7834, 0.7793, 0.7698, 0.8144, 0.7763],\n",
      "       device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([0.7750, 0.6484, 0.5939, 0.7784, 0.8080, 0.7870, 0.8046, 0.7804],\n",
      "       device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([0.7849, 0.7897, 0.7974, 0.7870, 0.7939, 0.7896, 0.7342, 0.7913],\n",
      "       device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "tensor([0.7673, 0.7786, 0.8419, 0.7648, 0.7517, 0.7902], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(y_test == 0))\n",
    "print(np.sum(y_test == 1))\n",
    "for X,y in simp_test_dataloader:\n",
    "    print(y)\n",
    "    print(torch.sigmoid(my_model(torch.transpose(X.to(device).float(), 1, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-device",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
